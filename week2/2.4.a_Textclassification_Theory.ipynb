{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Banner](./img/AI_Special_Program_Banner.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Theory - The Naive Bayes Method\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Naive Bayes method is explained below and illustrated using an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Conditional probabilities](#Conditional-probabilities)\n",
    "- [The Bayes theorem](#The-Bayes-theorem)\n",
    "    - [Practical implementation](#Practical-implementation)\n",
    "    - [Laplace smoothing](#Laplace-smoothing)\n",
    "- [Learning outcomes](#Learning-outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The naive Bayes method first makes some simplifying\n",
    "assumptions and then uses the *<span\n",
    "style=\"font-variant:small-caps;\">Bayes</span> theorem* to derive decisions from basic statistics\n",
    "(essentially relative frequencies). These\n",
    "are based on calculations of *conditional probabilities*, which are estimated from the relative frequencies of the training data $\\mathcal{T}$. In a sense, Commissioner Chance is replaced by\n",
    "Inspector <span style=\"font-variant:small-caps;\">Bayes</span>,\n",
    "who first collects evidence, then evaluates them with\n",
    "probabilities and finally determines the main suspect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional probabilities\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to use evidence in this form, we will first\n",
    "introduce the usual notation for conditional probabilities. The available indices are represented by a data set\n",
    "$\\mathbf{x}=(x_1,x_2,\\dots,x_m)$. Now the question is whether $\\mathbf{x}$ belongs to a\n",
    "certain class, such as $y^*$. It is then a matter of calculating the *conditional probability* for $y^*$ under the\n",
    "condition that the evidence $\\mathbf{x}$ is present. The conditional probability is represented as\n",
    "$$\n",
    "P(y^*\\mid \\mathbf{x}) := \\frac{P(y^*\\cap \\mathbf{x})}{P(\\mathbf{x})}\\qquad\\text{(1)}\n",
    "$$\n",
    "The right-hand side of the\n",
    "definition equation (1) shows the definition of the conditional\n",
    "probability. This is therefore obtained by calculating the\n",
    "probability that $\\mathbf{x}$ actually belongs to $y^*$, divided by\n",
    "the probability for $\\mathbf{x}$.\n",
    "\n",
    "$P(y^*\\mid \\mathbf{x})$ is also referred to as *a-posteriori probability*\n",
    "as this can only be calculated after the evidence is available. In contrast, $P(y^*)$ would be the *a-priori probability* of the\n",
    "class $y^*$, i.e. the probability for $y^*$ without further\n",
    "knowledge, i.e. without special evidence. The naive Bayes classifier\n",
    "would then choose the class $y^{\\text{max}}$ which has the strongest evidence.\n",
    "\n",
    "In the further lecture, it is now important to also consider the conditional\n",
    "probabilities $P(\\mathbf{x}\\mid y^*)$, i.e. the probability of finding the dataset\n",
    "$\\mathbf{x}$, given the associated class $y^*$. This can be derived from the\n",
    "Database $\\mathcal{D}$ under certain assumptions in the same way as the\n",
    "a-priori probability $P(y^*)$. The required conditional\n",
    "probability for $y^*$ is then obtained with the help of the <span style=\"font-variant:small-caps;\">Bayes</span> theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The <span style=\"font-variant:small-caps;\">Bayes</span> theorem\n",
    "---\n",
    "Equation (1) has the problem that neither the numerator nor the denominator\n",
    "can be calculated efficiently. The situation is improved by\n",
    "equation (2):\n",
    "\n",
    "  $$\n",
    "   P(y^*\\mid \\mathbf{x}) = \\frac{P(\\mathbf{x}\\mid y^*)\\cdot P(y^*)}{P(\\mathbf{x})}\\qquad\\text{(2)}\n",
    "  $$\n",
    "\n",
    "This is\n",
    "the <span style=\"font-variant:small-caps;\">Bayes</span> theorem,\n",
    "which is actually just a clever transformation. Thus\n",
    "the proof of the theorem is very simple, because according to the definition of the\n",
    "conditional probability the following applies:\n",
    "\n",
    "  $$\n",
    "   P(y^*\\cap \\mathbf{x}) = \\frac{P(y^*\\cap \\mathbf{x})}{P(y^*)}\\cdot P(y^*) = P(\\mathbf{x}\\mid y^*)\\cdot P(y^*)\n",
    "  $$\n",
    "  \n",
    "If this is now inserted into equation (1), the result is\n",
    "equation (2), i.e. the  <span\n",
    "style=\"font-variant:small-caps;\">Bayes</span> theorem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question now is what can be gained from this. First of all, you realize\n",
    "that the question of the class $y^{\\text{max}}$ with the highest\n",
    "a-posteriori probability is reduced to finding the expression\n",
    "  $$\n",
    "  I(\\mathbf{x},y^*) := P(\\mathbf{x}\\mid y^*)\\cdot P(y^*)\n",
    "  $$\n",
    "to maximize the numerator from the <span style=\"font-variant:small-caps;\">Bayes</span> theorem. The denominator\n",
    "is not needed because it is the same for all a-posteriori probabilities to be compared, as the data set under consideration is\n",
    "$$\n",
    "\\mathbf{x} = (x_1,x_2,\\dots,x_m)\n",
    "$$\n",
    "is always the same.\n",
    "Therefore, the expression in the denominator would only scale the values.\n",
    "We want to call $I(\\mathbf{x},y^*)$ the *indicative strength* of $\\mathbf{x}$ for $y^*$.\n",
    "So now the question is how the strength of the evidence can be calculated easily. It turns out that all you have to do is\n",
    "count and do some fractional arithmetic based on an **idea** or **naive assumption**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">At this point, **naivety** comes into play by assuming that all attributes or attribute values are ***independent*** and ***equally important***. Although this is unrealistic, but leads to a procedure that is easy to calculate! From the point of view of\n",
    "probability theory, a dataset $\\mathbf{x}$ is created from the *independent\n",
    "events* in which the attributes $A_i$ assume the values $x_i$ for $i=1,\\dots,\\mu$. Thus\n",
    "$P(\\mathbf{x}\\mid y^*)$ can be calculated as follows:\n",
    "\n",
    "  $$\n",
    "  P(\\mathbf{x}\\mid y^*) = P(A_1=x_1\\mid y^*)\\cdot P(A_2=x_2\\mid y^*) \\cdot\\ldots\\cdot P(A_m=x_m\\mid y^*)\n",
    "  $$\n",
    "\n",
    ">i.e. the conditional probability for the dataset $\\mathbf{x}$ for a given class $y^*$ results\n",
    "as the product of the conditional individual probabilities for the assumption of a certain value of\n",
    "an attribute for a given class $y^*$. The strength of evidence $I(\\mathbf{x},y^*)$ can therefore be calculated as follows:\n",
    "\n",
    "  $$\n",
    "  I(\\mathbf{x},y^*) = \\prod_{i=1}^m P(A_i=x_i\\mid y^*)\\cdot P(y^*)\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting estimates for the individual probabilities $P(A_i=x_i\\mid y^*)$ as well as for\n",
    "the a-priori probability $P(y^*)$ is now easy by calculating the (absolute and relative) frequencies from the training data $\\mathcal{T}$. To do this, we need the\n",
    "notation introduced in the formalization of the classification problem.\n",
    "\n",
    "Thus, the a-priori probabilities (or estimates of them) are obtained by\n",
    "dividing the absolute frequencies of the individual classes by the number of data records (or samples), i.e.\n",
    "$$\n",
    "P(y_k)=\\frac{p_k}{n_t}\\>.\n",
    "$$\n",
    "The conditional probabilities are similar:\n",
    "$$\n",
    "P(A_i=a_{i,j}\\mid y_k)=\\frac{P(A_i=a_{i,j}\\wedge y_k)}{P(y_k)}=\n",
    "      \\frac{\\frac{{p_{k,i,j}}}{n_t}}{\\frac{{p_k}}{n_t}}=\\frac{{p_{k,i,j}}}{{p_k}}\n",
    "$$\n",
    "This provides all the ingredients for the classifier.\n",
    "\n",
    "For the binary case in particular, only one of the two classes $y_1$\n",
    "or $y_2$ must be selected and the calculations for the respective\n",
    "other class would be symmetrical. The selected class is denoted by\n",
    "$y^*$. For the voucher example, this is the *Yes* class, i.e. the new order placed within 90 days. With this\n",
    "the values in the following table are obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table: Basic statistics and estimators for conditional probabilities for voucher dispatch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| attribute ($\\mathbf{A_i}$) | attribute value | $S_1$ | $S_2$ | $W_1$ | $W_2$ |\n",
    "|-------------------|--------------|-------|-------|-------|-------|\n",
    "| **delay** | *(1) long* | 2 | 3 | 2/9 | 3/5 |\n",
    "| | *(2) short* | 3 | 2 | 3/9 | 2/5 |\n",
    "| | *(3) none* | 4 | 0 | 4/9 | 0 |\n",
    "| **Customer** | *(1) C* | 3 | 1 | 3/9 | 1/5 |\n",
    "| | *(2) F* | 4 | 2 | 4/9 | 2/5 |\n",
    "| | *(3) M* | 2 | 2 | 2/9 | 2/5 |\n",
    "| **item** | *(1) multiple* | 6 | 1 | 6/9 | 1/5 |\n",
    "| | *(2) single* | 3 | 4 | 3/9 | 4/5 |\n",
    "| **return** | *(1) no* | 6 | 2 | 6/9 | 2/5 |\n",
    "| | *(2) yes* | 3 | 3 | 3/9 | 3/5 |\n",
    "| **c: New order?** | | **9** | **5** | **9/14** | **5/14** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legend:\n",
    "* $S_1 = p_{i,j}^*$\n",
    "* $S_2 = {n_{i,j}^*}$\n",
    "* $W_1 = P(a_{i,j}\\mid\\text{yes})$\n",
    "* $W_2 = P(a_{i,j}\\mid\\text{no})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction\n",
    "Assuming there is a new sample in the form of the dataset\n",
    "$\\mathbf{x}_{\\text{new}}=(\\text{long, C, multiple, no})$. Then we get\n",
    "as the strength of the evidence\n",
    "\n",
    "$$\\begin{array}{rll}\n",
    " I(\\mathbf{x}_{\\text{new}},\\text{Yes}) &=\n",
    " \\frac29\\cdot\\frac39\\cdot\\frac69\\cdot\\frac69\\cdot{\\mathbf{\\frac9{14}}}=\\frac4{189}=0,0211\\\\\n",
    " I(\\mathbf{x}_{\\text{new}},\\text{No}) &=\n",
    " \\frac35\\cdot\\frac15\\cdot\\frac15\\cdot\\frac25\\cdot{\\mathbf{\\frac5{14}}}=\\frac3{875}=0,0034\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "This means that the evidence is approx. 6 times stronger in favor of a new order than against it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values\n",
    "\n",
    "Now assume that the sample\n",
    "$\\mathbf{x}_{\\text{missing}}=(\\text{?, M, single, yes})$ would have to be classified,\n",
    "i.e. a sample in which the value for `delay` is missing or is unknown. This is *unproblematic* for the naive Bayes classifier: the unknown value is simply ignored and the indices that are available are used.  \n",
    "This results in the evidence strengths\n",
    "\n",
    "$$\n",
    "\\begin{array}{rll}\n",
    " I(\\mathbf{x}_{\\text{missing}},\\text{Yes}) &=\n",
    "  \\frac29\\cdot\\frac39\\cdot\\frac39\\cdot{\\mathbf{\\frac9{14}}}=\\frac1{63}=0,0159\\\\\n",
    " I(\\mathbf{x}_{\\text{missing}},\\text{No}) &=\n",
    "  \\frac25\\cdot\\frac45\\cdot\\frac35\\cdot{\\mathbf{\\frac5{14}}}=\\frac{12}{175}=0,0686\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "So this time everything indicates that the customer will not order again within the 90-day period. On closer inspection\n",
    "you can even see that every single one of the existing indications speaks for the no-case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace smoothing\n",
    "\n",
    "But what happens if it becomes known that there was no delay?\n",
    "i.e. the data set becomes $\\mathbf{x}_0=(\\text{none, M, single, yes})\\>.$ In the\n",
    "yes-case, the above strength of evidence is\n",
    "is simply multiplied by $4/9$, but in the no-case by $0$! The latter\n",
    "means that the total strength of evidence for the no-case is 0,\n",
    "although three of the four clues speak in favor of this case. This\n",
    "completely contradicts intuition, and fortunately there is a simple way out: the <span\n",
    "style=\"font-variant:small-caps;\">Laplace</span> correction. This is\n",
    "an impressively simple trick in and of itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The associated **idea** is quite simple: instead of calculating the absolute frequencies by\n",
    "you start counting at 0, you start at 1! This leads to an addition of 1 to the actual absolute frequencies for each of the $m_i$ values $a_{i,j}$ of an attribute $A_i$, so that the following \n",
    "<span style=\"font-variant:small-caps;\">Laplace</span> estimation for the conditional individual probabilities is given:\n",
    "\n",
    "$$\n",
    "P(A_i=a_{i,j}\\mid y_k)=\\frac{p_{k,i,j}+1}{p_k+m_i}\n",
    "$$\n",
    "\n",
    ">Note that, of course, the a-priori probabilities do not require such a correction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This would replace the original table above with the following\n",
    "table with the <span style=\"font-variant:small-caps;\">Laplace</span>-corrected estimates\n",
    "for the conditional individual probabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table: Laplace-corrected probabilities for voucher dispatch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| attribute ($\\mathbf{A_i}$) | attribute value | $S_1$ | $S_2$ | $W_1$ | $W_2$ |\n",
    "|-------------------|--------------|-------|-------|-------|-------|\n",
    "| **delay** | *(1) long* | 3 | 4 | 3/12 | 4/8 |\n",
    "| | *(2) short* | 4 | 3 | 4/12 | 3/8 |\n",
    "| | *(3) none* | 5 | 1 | 5/12 | 1/8 |\n",
    "| | $p^{(k)}+m_1$ | **12** | **8** | | |\n",
    "| **Customer** | *(1) U* | 4 | 2 | 4/12 | 2/8 |\n",
    "| | *(2) F* | 5 | 3 | 5/12 | 3/8 |\n",
    "| | *(3) M* | 3 | 3 | 3/12 | 3/8 |\n",
    "| | $p^{(k)}+m_2$ | **12** | **8** | | |\n",
    "| **item** | *(1) multiple* | 7 | 2 | 7/11 | 2/7 |\n",
    "| | *(2) single* | 4 | 5 | 4/11 | 5/7 |\n",
    "| | $p^{(k)}+m_3$ | **11** | **7** | | |\n",
    "| **return** | *(1) no* | 7 | 3 | 7/11 | 3/7 |\n",
    "| | *(2) yes* | 4 | 4 | 4/11 | 4/7 |\n",
    "| | $p^{(k)}+m_4$ | **11** | **7** | | |\n",
    "| **c: New order?** | | **9** | **5** | **9/14** | **5/14** |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legend:\n",
    "  * $S_1 = p_{i,j}^*+1$\n",
    "  * $S_2 = {n_{i,j}^*}+1$\n",
    "  * $W_1 = P(a_{i,j}\\mid\\text{yes})$\n",
    "  * $W_2 = P(a_{i,j}\\mid\\text{no})$\n",
    "\n",
    "This results in the following strengths of evidence:\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    " I(\\mathbf{x}_0,\\text{yes}) &=\n",
    "  \\frac5{12}\\cdot\\frac3{12}\\cdot\\frac4{11}\\cdot\\frac4{11}\\cdot{\\mathbf{\\frac9{14}}}=\\frac{15}{1694}=0,0088\\\\\n",
    " I(\\mathbf{x}_0,\\text{No}) &=\n",
    "  \\frac18\\cdot\\frac38\\cdot\\frac57\\cdot\\frac47\\cdot{\\mathbf{\\frac5{14}}}=\\frac{75}{10976}=0,0068\n",
    "\\end{array}\n",
    "$$\n",
    "As you can see, the <span\n",
    "style=\"font-variant:small-caps;\">Laplace</span> correction can not fully compensate\n",
    "the effect of the dominance of the `delay` attribute in this case; one would expect a new order to be placed instead of the correction, since the effect of a punctual delivery is so strong according to the data.\n",
    "\n",
    "In general, however, it can be stated that the initialization\n",
    "of the count of absolute frequencies with 1 is not necessary.\n",
    "Rather, any value $\\lambda\\in\\mathbb{R}$ can be used for initialization\n",
    "which would then serve as the estimator for the conditional individual probabilities would result:\n",
    "$$\n",
    "P(A_i=a_{i,j}\\mid y_k)=\\frac{{p_{k,i,j}}+\\lambda}{{p_k+\\lambda\\cdot m_i}}\n",
    "$$\n",
    "By varying the parameter $\\lambda$, the behavior of the naive Bayesian method can be *optimized*.\n",
    "\n",
    "The naive Bayes method therefore makes a class prediction based on (estimated) probabilities for the class. In contrast *rules* are created for decision trees, for example, or the KNN method remains *lazy* and only becomes active\n",
    "when a sample is to be classified. However, these methods are also based on (relative) frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning outcomes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important learning objectives of this unit at a glance:\n",
    "\n",
    "* Text classification with a naive Bayes model heavily relies on conditional probabilities,\n",
    "* To efficiently calculate these conditional probabilities, a naive assumption is made about the independence and equal importance of attributes,\n",
    "* This is unrealistic, but leads to efficient calculations and the models are still strong in practice,\n",
    "* To deal with a possible division by 0, the laplace smoothing can be used to mitigate the problem."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

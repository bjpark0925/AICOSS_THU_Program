{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcb6c2b1-43c8-4551-a482-d667aeb7ee59",
   "metadata": {},
   "source": [
    "![Banner](img/AI_Special_Program_Banner.jpg)\n",
    "\n",
    "## Hyperparameter Optimization (HPO) w/ Optuna - Material\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526d0083-e1d0-41d4-9063-93eba91b1efe",
   "metadata": {
    "tags": []
   },
   "source": [
    "***Data Source**: [Kaggle](https://www.kaggle.com/datasets/andrewmvd/fetal-health-classification)*\n",
    "\n",
    "***Optuna Documentation**: [https://optuna.readthedocs.io/en/stable/](https://optuna.readthedocs.io/en/stable/)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee23dbe-7417-4003-bb44-56f8a16a953d",
   "metadata": {},
   "source": [
    "Hyperparameter optimization (HPO) is a critical aspect of machine learning that involves selecting a set of optimal hyperparameters for a learning algorithm. Hyperparameters are the configuration settings used to tune how the algorithm learns. Unlike model parameters, which are learned during training, hyperparameters are set prior to the training process and have a significant impact on the outcome of machine learning models.\n",
    "\n",
    "The process of hyperparameter optimization seeks to find the combination of hyperparameters that yields the best performance, as measured by a predefined score or objective function. This is particularly important in complex models like deep neural networks, where the number of hyperparameters can be quite large, and the right set of values can dramatically improve this performance.\n",
    "\n",
    "Several techniques have been developed for hyperparameter optimization, including:\n",
    "\n",
    "1. **Grid Search:** A brute-force approach that evaluates all possible combinations of hyperparameters.\n",
    "2. **Random Search:** Evaluates a random selection of hyperparameters, which can sometimes lead to better results in less time than grid search.\n",
    "3. **Bayesian Optimization:** Uses a probabilistic model to guide the search for the best hyperparameters and is often more efficient than random or grid search.\n",
    "4. **Gradient-based Optimization:** Adjusts hyperparameters using gradient descent methods.\n",
    "\n",
    "The choice of technique depends on the specific problem, the type of model, the nature of the search space, and computational resources. As models and datasets become more complex, efficient hyperparameter optimization becomes increasingly important to achieve the best results.\n",
    "\n",
    "In this module, we will explore how hyperparameter optimization can be applied to improve overall model performance. We will look at various strategies to do so, understand their trade-offs, and learn how to implement them effectively. Specifically, for this class we will be working with a Python library called Optuna, an open-source hyperparameter optimization framework that automates the process of finding the best hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342d6592-3fb7-4f5d-98f5-fa8f028e7348",
   "metadata": {},
   "source": [
    "The contents of this notebook are split into two major parts:\n",
    "- **Part I**: Solving a classification problem without any automatic hyperparameter tuning (manual tuning possible)\n",
    "- **Part II**: Solving the same problem, but applying automatic hyperparameter tuning instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f9cd32-a2d8-403c-b0f1-848f07abbfd0",
   "metadata": {},
   "source": [
    "## Overview\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34718e0e-cdf5-4116-8811-3f913695a3f5",
   "metadata": {},
   "source": [
    "* [Part I](#Part-I)\n",
    "* [Part II](#Part-II)\n",
    "    * [Study & Objective Function](#Study-&-Objective-Function)\n",
    "    * [Neural Architecture Search (NAS)](#Neural-Architecture-Search-(NAS))\n",
    "    * [Trial Pruning](#Trial-Pruning)\n",
    "    * [Optuna Visualizations](#Optuna-Visualizations)\n",
    "* [Learning Outcomes](#Learning-Outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d9d42c-1a9e-4183-93b2-8c1e420a4463",
   "metadata": {},
   "source": [
    "## Part I\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daa9ec8-0e85-451a-b0e8-dcf15ea375d9",
   "metadata": {},
   "source": [
    "> **Library imports and general settings**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0c9938-0ca2-4715-ac44-63f5af1ba393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.389474Z",
     "start_time": "2024-01-07T16:45:05.916416Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e74db7-34da-4c26-80df-20a03078e958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.394637Z",
     "start_time": "2024-01-07T16:45:07.389465Z"
    }
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "CLASSES = 3\n",
    "\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e15fea7-7cb1-4bc1-8611-e1e05cf0c30c",
   "metadata": {},
   "source": [
    "> **Definition of (selected) hyperparameters**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29646f1-8945-4fd8-883c-fb5b68c6548b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.403099Z",
     "start_time": "2024-01-07T16:45:07.390613Z"
    }
   },
   "outputs": [],
   "source": [
    "NN_ARCHITECTURE = [15, 10] # representing the number of neurons for the first (index 0) and second hidden layer (index 1)\n",
    "BATCH_SIZE = 100\n",
    "OPTIMIZER = 'Adam' # SGD vs. Adam vs. RMSprop\n",
    "LEARNING_RATE = 1\n",
    "WEIGHT_DECAY = 1\n",
    "SCHEDULER = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0312904-0dad-4e04-854b-c3692f1a6c24",
   "metadata": {},
   "source": [
    "<img src='img/HPO_NN_Architecture.svg'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ed8c28-1cf9-4983-96d6-7ad8c4e55f7c",
   "metadata": {},
   "source": [
    "> **Data preparation**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53f4d9f-3994-4784-aae4-8a1c7e2e2462",
   "metadata": {},
   "source": [
    "Our chosen use-case is looking at tabular (very unbalanced) health data for fetal health classification (normal, suspect, pathological). However, we are not so much interested in the use-case itself. Instead, we are trying to figure out a way to train a model with optimized parameters. Apart from being unbalanced, the data at hand is already cleaned and does not have any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a208c069-1d47-4e8a-a31f-8ac1aaca3fe0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.444291Z",
     "start_time": "2024-01-07T16:45:07.392273Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/HPO_Data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d441d27b-ffc8-4932-bc4a-f6b7ae956411",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.445609Z",
     "start_time": "2024-01-07T16:45:07.422159Z"
    }
   },
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f10486-ef67-42ed-917b-7a00a54b3519",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.446764Z",
     "start_time": "2024-01-07T16:45:07.431967Z"
    }
   },
   "outputs": [],
   "source": [
    "data.isnull().any().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d7662b-c01c-4949-ba4a-8bd287f1019c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.525089Z",
     "start_time": "2024-01-07T16:45:07.454714Z"
    }
   },
   "outputs": [],
   "source": [
    "data.fetal_health.value_counts().plot(kind='bar')\n",
    "plt.show()\n",
    "data.fetal_health.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c9d5e4-fe27-4b41-ad77-5c44d41c505f",
   "metadata": {},
   "source": [
    "Due to data being this unbalanced, the observed null accuracy is already quite high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f3fe70-4bce-4df6-ae6f-a043afbc3c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.526062Z",
     "start_time": "2024-01-07T16:45:07.515415Z"
    }
   },
   "outputs": [],
   "source": [
    "null_accuracy = data.fetal_health.value_counts()[1.0]/len(data)\n",
    "null_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5066a2d2-ce45-4e31-9877-17a36a592cf3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.543393Z",
     "start_time": "2024-01-07T16:45:07.519805Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = OrdinalEncoder()\n",
    "oe_columns = ['fetal_health']\n",
    "encoder.fit(data[oe_columns])\n",
    "data[oe_columns] = encoder.transform(data[oe_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469780ed-b1b6-4299-a569-bbe1a278d034",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.581809Z",
     "start_time": "2024-01-07T16:45:07.531164Z"
    }
   },
   "outputs": [],
   "source": [
    "data.fetal_health.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef90c0-6041-4556-8585-a9050427fed8",
   "metadata": {},
   "source": [
    "> **Creating helper classes and methods**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d745fc7-b87e-400b-be7c-efd18690749b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.584035Z",
     "start_time": "2024-01-07T16:45:07.543133Z"
    }
   },
   "outputs": [],
   "source": [
    "class FetalHealthData(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.labels = data.fetal_health.tolist()\n",
    "        self.features = data.drop(columns=['fetal_health'], axis=1).values.tolist()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = np.array(self.features[index]), np.array(self.labels[index])\n",
    "        return sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf81872-ff3b-4a3c-b5e5-b9d06965400d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.585364Z",
     "start_time": "2024-01-07T16:45:07.554622Z"
    }
   },
   "outputs": [],
   "source": [
    "# HP: Hidden Layer 0, Hidden Layer 1\n",
    "def get_model():\n",
    "    \n",
    "    ###\n",
    "    layer_0 = NN_ARCHITECTURE[0]\n",
    "    layer_1 = NN_ARCHITECTURE[1]\n",
    "    ###\n",
    "    \n",
    "    layers = list()\n",
    "    \n",
    "    # 21 Input Features\n",
    "    in_features = len(data.drop(columns=['fetal_health'], axis=1).columns)\n",
    "    \n",
    "    # Input Layer -> Hidden Layer 0\n",
    "    layers.append(nn.Linear(in_features, layer_0))\n",
    "    layers.append(nn.LeakyReLU())\n",
    "    \n",
    "    # Hidden Layer 0 -> Hidden Layer 1\n",
    "    layers.append(nn.Linear(layer_0, layer_1))\n",
    "    layers.append(nn.LeakyReLU())\n",
    "    \n",
    "    # Hidden Layer 1 -> Output Layer (3 Classes)\n",
    "    layers.append(nn.Dropout())\n",
    "    layers.append(nn.Linear(layer_1, CLASSES))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409dfc39-4b8d-4ab8-a624-75c154dc7588",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.586563Z",
     "start_time": "2024-01-07T16:45:07.565346Z"
    }
   },
   "outputs": [],
   "source": [
    "# HP: Batch Size\n",
    "def get_data():\n",
    "    \n",
    "    ###\n",
    "    batch_size = BATCH_SIZE\n",
    "    ###\n",
    "    \n",
    "    training_data, testing_data = train_test_split(data, test_size=0.2, random_state=RANDOM_SEED, stratify=data.fetal_health)\n",
    "    training_data, testing_data = FetalHealthData(training_data), FetalHealthData(testing_data)\n",
    "    return torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True), torch.utils.data.DataLoader(testing_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb0a9e0-7b2b-4fc1-ba58-19e6763f9a35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.607354Z",
     "start_time": "2024-01-07T16:45:07.577563Z"
    }
   },
   "outputs": [],
   "source": [
    "# HP: Optimizer, Learning Rate, Weight Decay\n",
    "def get_optimizer(model):\n",
    "    \n",
    "    ###\n",
    "    optimizer = OPTIMIZER\n",
    "    learning_rate = LEARNING_RATE\n",
    "    weight_decay = WEIGHT_DECAY\n",
    "    ###\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        return torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    elif optimizer == 'SGD':\n",
    "        return torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        return torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c05bf2-3aa1-4b29-8c3f-061a33dccb8d",
   "metadata": {},
   "source": [
    "> **Creating training loop**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a700c21-719b-4ff6-bb5c-44ca5696ff6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:07.614716Z",
     "start_time": "2024-01-07T16:45:07.590890Z"
    }
   },
   "outputs": [],
   "source": [
    "# HP: Scheduler\n",
    "def train(model, training_batches, testing_batches):\n",
    "    ###\n",
    "    scheduler = SCHEDULER\n",
    "    ###\n",
    "    \n",
    "    accuracy = list()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = get_optimizer(model)\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler = CosineAnnealingLR(optimizer, EPOCHS-1, verbose=False)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        ### Training\n",
    "        model.train()\n",
    "        for samples, labels in training_batches:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(samples.float())\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "            \n",
    "        num_samples = 0\n",
    "        correct_predictions = 0\n",
    "        ### Testing\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for samples, labels in testing_batches:\n",
    "                output = model(samples.float())\n",
    "                correct_predictions += (output.argmax(dim=1) == labels).sum().item()\n",
    "                num_samples += labels.size(0)\n",
    "            \n",
    "        accuracy.append(100.0 * correct_predictions / num_samples)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1286c427-f2e9-4834-8305-6787046dc538",
   "metadata": {},
   "source": [
    "> **Training & evaluation**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01bd155-4250-4866-ae2a-530bd7f6e98c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:09.543711Z",
     "start_time": "2024-01-07T16:45:07.602281Z"
    }
   },
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "training_batches, testing_batches = get_data()\n",
    "history = train(model, training_batches, testing_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3ee36c-b95e-452d-835c-52a223263997",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:09.647694Z",
     "start_time": "2024-01-07T16:45:09.574638Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(history)\n",
    "plt.ylabel('validation accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6732581d-e268-471b-8e8b-67c36c614551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:09.648869Z",
     "start_time": "2024-01-07T16:45:09.646381Z"
    }
   },
   "outputs": [],
   "source": [
    "history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33e158e-6c71-4d59-b60a-0cc3a2eeadfb",
   "metadata": {},
   "source": [
    "If you made no changes to the preset parameters you can see that the performance of the training outcome is not great. In fact, prediction accuracy does not exceed null accuracy which makes the model rather useless.\n",
    "\n",
    "**Exercise:** Go back to the initial definition of the hyperparameters at the beginning of this notebook. Finetune those parameters manually. How do you decide for meaningful values? How does your model perform after you manually set new parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dc3c46-0525-4f05-9538-e09c4b181f18",
   "metadata": {},
   "source": [
    "## Part II\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09fa45f0-d883-4d70-9032-d9af7a2ef89e",
   "metadata": {},
   "source": [
    "### Study & Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1633e94-aa76-4b8c-98d0-0cf41d438485",
   "metadata": {},
   "source": [
    "To get an Optuna pipeline running, usually the first steps should be:\n",
    "* To define a **study object** which describes the intent and used methodology for the optimization process\n",
    "* To create an **objective function** that receives updates on the model's fitness/performance during training\n",
    "* To declare valid ranges and values for selected parameters\n",
    "* To run the study for a given number of **trials** in which optimization is performed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594f900b-15c2-40f5-bb95-ab5eff8476ae",
   "metadata": {},
   "source": [
    "> **Adding needed libraries**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d406a-e1c7-4b47-bf6c-bab028f6fb73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:09.775846Z",
     "start_time": "2024-01-07T16:45:09.647863Z"
    }
   },
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d46dfba-bf62-4bcd-a351-529674b47e09",
   "metadata": {},
   "source": [
    "> **Creating a study object (in memory)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e5976b-bf07-43ad-9fb5-a303a39cc293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:09.816122Z",
     "start_time": "2024-01-07T16:45:09.777144Z"
    }
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e928c5-12ab-4fb3-9a93-8c1713f63307",
   "metadata": {},
   "source": [
    "> **Changing existing function definitions to accept tuned parameters**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e476ac21-0bc5-4c98-a3e6-13a118a0744d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:09.857538Z",
     "start_time": "2024-01-07T16:45:09.854459Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(params):\n",
    "    ###\n",
    "    layer_0 = params['layer_0']\n",
    "    layer_1 = params['layer_1']\n",
    "    ###\n",
    "    \n",
    "    layers = list()\n",
    "    \n",
    "    # 21 Input Features\n",
    "    in_features = len(data.drop(columns=['fetal_health'], axis=1).columns)\n",
    "    \n",
    "    # Input Layer -> Hidden Layer 0\n",
    "    layers.append(nn.Linear(in_features, layer_0))\n",
    "    layers.append(nn.LeakyReLU())\n",
    "    \n",
    "    # Hidden Layer 0 -> Hidden Layer 1\n",
    "    layers.append(nn.Linear(layer_0, layer_1))\n",
    "    layers.append(nn.LeakyReLU())\n",
    "    \n",
    "    # Hidden Layer 1 -> Output Layer (3 Classes)\n",
    "    layers.append(nn.Dropout())\n",
    "    layers.append(nn.Linear(layer_1, CLASSES))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d986c20-3f2f-4063-989a-a2faac3ec274",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:09.870021Z",
     "start_time": "2024-01-07T16:45:09.856552Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_data(params):\n",
    "    ###\n",
    "    batch_size = params['batch_size']\n",
    "    ###\n",
    "    \n",
    "    training_data, testing_data = train_test_split(data, test_size=0.2, random_state=RANDOM_SEED, stratify=data.fetal_health)\n",
    "    training_data, testing_data = FetalHealthData(training_data), FetalHealthData(testing_data)\n",
    "    return torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True), torch.utils.data.DataLoader(testing_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be10f05b-2a46-4214-a0b4-2d91f4f0c2ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:09.887228Z",
     "start_time": "2024-01-07T16:45:09.869996Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_optimizer(model, params):\n",
    "    ###\n",
    "    optimizer = params['optimizer']\n",
    "    learning_rate = params['learning_rate']\n",
    "    weight_decay = params['weight_decay']\n",
    "    ###\n",
    "    \n",
    "    if optimizer == 'Adam':\n",
    "        return torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    elif optimizer == 'SGD':\n",
    "        return torch.optim.SGD(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    elif optimizer == 'RMSprop':\n",
    "        return torch.optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "    \n",
    "    # To make things shorter, this would be an alternative way to achieve the same thing:\n",
    "    # return getattr(optim, optimizer)(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39715b4-2798-4035-a558-456d9168dc29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:09.892522Z",
     "start_time": "2024-01-07T16:45:09.879477Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, training_batches, testing_batches, params):\n",
    "    ###\n",
    "    scheduler = params['scheduler']\n",
    "    ###\n",
    "    \n",
    "    accuracy = list()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    ###\n",
    "    optimizer = get_optimizer(model, params)\n",
    "    ###\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler = CosineAnnealingLR(optimizer, EPOCHS-1, verbose=False)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        ### Training\n",
    "        model.train()\n",
    "        for samples, labels in training_batches:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(samples.float())\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "        \n",
    "        num_samples = 0\n",
    "        correct_predictions = 0\n",
    "        ### Testing\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for samples, labels in testing_batches:\n",
    "                output = model(samples.float())\n",
    "                correct_predictions += (output.argmax(dim=1) == labels).sum().item()\n",
    "                num_samples += labels.size(0)\n",
    "            \n",
    "        accuracy.append(100.0 * correct_predictions / num_samples)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc83bf5-8872-4928-bb50-7ea43f7bbc49",
   "metadata": {},
   "source": [
    "> **Defining an objective function that includes hyperparameters and their valid ranges**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c355f9b-0cda-4630-b738-011248a17c84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:09.915168Z",
     "start_time": "2024-01-07T16:45:09.892366Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'layer_0': trial.suggest_int('layer_0', 8, 256),\n",
    "        'layer_1': trial.suggest_int('layer_1', 8, 256),\n",
    "        'batch_size': trial.suggest_int('batch_size', 8, 128),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['SGD', 'Adam', 'RMSprop']),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "        'weight_decay': trial.suggest_loguniform('weight_decay', 1e-5, 1e-1),\n",
    "        'scheduler': True if trial.suggest_int('scheduler', 0, 1) == 1 else False\n",
    "    }\n",
    "    \n",
    "    model = get_model(params)\n",
    "    training_batches, testing_batches = get_data(params)\n",
    "    history = train(model, training_batches, testing_batches, params)\n",
    "    \n",
    "    # Fitness-Value\n",
    "    return history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb8ab7d-4e1b-421a-b105-5bada8800f63",
   "metadata": {},
   "source": [
    "> **Optimizing those parameters**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43afd73-9e87-4be4-be15-43ec3b9dd56b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:25.314645Z",
     "start_time": "2024-01-07T16:45:09.904552Z"
    }
   },
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e8fc1e-52d7-46a0-8c03-7105f33bf50a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:25.317967Z",
     "start_time": "2024-01-07T16:45:25.310483Z"
    }
   },
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a507113f-d465-4b02-88f7-f3c26cead055",
   "metadata": {},
   "source": [
    "### Neural Architecture Search (NAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66556022-c9a7-48c1-8138-ed2239c6472d",
   "metadata": {},
   "source": [
    "Optuna features a very powerful **define-by-run** principle which does not limit the user to a static model definition. Instead, it is possible to freely define the search space while the optimization is already being performed. This allows for adaptations to the model design (number of layers, neurons, etc.) - which could be considered a special set of hyperparameters. Because this kind of optimization deals with the network architecture itself, the process is specifically called **neural architecture search**. Following, we implement such a NAS on a very basic level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b976f931-ce12-47e0-8689-9d4da5b089b0",
   "metadata": {},
   "source": [
    "> **Changing model definition to be determined during runtime (including architecture related parameters)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac94bab-3c7e-4051-b04c-2a14a07f1fb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:45:25.335334Z",
     "start_time": "2024-01-07T16:45:25.311233Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model(trial):\n",
    "    # Suggesting Numbers of Hidden Layers\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 4)\n",
    "    \n",
    "    layers = list()\n",
    "    \n",
    "    # 21 Input Features\n",
    "    in_features = len(data.drop(columns=['fetal_health'], axis=1).columns)\n",
    "    \n",
    "    # Suggest Numbers of Neurons for each Hidden Layer\n",
    "    for layer in range(num_layers):\n",
    "        out_features = trial.suggest_int(f'layer_{layer}', 8, 256)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.LeakyReLU())\n",
    "        \n",
    "        in_features = out_features\n",
    "    \n",
    "    layers.append(nn.Dropout())\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b45c5a-8995-4c05-a478-8ab1a0b4bdec",
   "metadata": {},
   "source": [
    "> **Adapting objective function (removing architecture related parameters)**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0a285b-0c3a-4190-9037-d11f37508a07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:46:59.249341Z",
     "start_time": "2024-01-07T16:46:59.210142Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'batch_size': trial.suggest_int('batch_size', 8, 128),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['SGD', 'Adam', 'RMSprop']),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "        'weight_decay': trial.suggest_loguniform('weight_decay', 1e-5, 1e-1),\n",
    "        'scheduler': True if trial.suggest_int('scheduler', 0, 1) == 1 else False\n",
    "    }\n",
    "    \n",
    "    ###\n",
    "    model = get_model(trial)\n",
    "    ###\n",
    "    \n",
    "    training_batches, testing_batches = get_data(params)\n",
    "    history = train(model, training_batches, testing_batches, params)\n",
    "    \n",
    "    # Fitness-Value\n",
    "    return history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7aef772-4bc9-4e99-8eda-b8ea9ca93e7b",
   "metadata": {},
   "source": [
    "> **Running the study with varying number of hidden layers**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c375623-5fd0-4873-b63a-8f6d23d0aa6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:47:17.380108Z",
     "start_time": "2024-01-07T16:47:01.268028Z"
    }
   },
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbde604-fad1-4e8a-9135-b702ed88e958",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:47:34.057943Z",
     "start_time": "2024-01-07T16:47:34.012989Z"
    }
   },
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d525b8-cac2-4cec-8c79-28a26e53fa8c",
   "metadata": {},
   "source": [
    "> **Continuing parameter search**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe15e36-e935-4b0f-ae13-2399d96f0632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:48:02.084267Z",
     "start_time": "2024-01-07T16:47:35.456742Z"
    }
   },
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369faa54-b30c-445a-bff7-2284e365b916",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:48:02.087504Z",
     "start_time": "2024-01-07T16:48:02.083639Z"
    }
   },
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74757505-ca9d-49ce-8b5c-e845f251abb1",
   "metadata": {},
   "source": [
    "Remarkably, after only a few trials, we were able to come up with a set of hyperparameters resulting in a majorly improved prediction accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7183c9-ee3b-4dd2-8718-be28293282b5",
   "metadata": {},
   "source": [
    "### Trial Pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d688ce01-0c73-4016-b638-206a817d6541",
   "metadata": {},
   "source": [
    "Another aspect of Optuna's vast functionality, is its ability to let go of unpromising trials. This technique - called pruning - allows to focus on good sets of parameters only and might speed up the optimization process dramatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7635c88c-8e30-4d72-b8cb-ea1168b3f361",
   "metadata": {},
   "source": [
    "> **Create a new study object that includes a pruning strategy and can be persisted on disc**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db7ef1e-b080-4850-a3ed-07b02d2aef1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:48:02.335631Z",
     "start_time": "2024-01-07T16:48:02.119835Z"
    }
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction='maximize',\n",
    "    sampler=optuna.samplers.TPESampler(seed=RANDOM_SEED),\n",
    "    pruner=optuna.pruners.MedianPruner(),\n",
    "    study_name='Fetal_Health_Study',\n",
    "    storage='sqlite:///data/Fetal_Health.sqlite3',\n",
    "    load_if_exists=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a34fe5-436a-472f-a397-d3ec24b7f7a5",
   "metadata": {},
   "source": [
    "> **Enable feedback on fitness value (accuracy) during training and apply pruning strategy**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832a2bb7-2373-469b-8621-9710e370e71f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:48:02.337619Z",
     "start_time": "2024-01-07T16:48:02.333473Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, training_batches, testing_batches, params, trial):\n",
    "    ###\n",
    "    scheduler = params['scheduler']\n",
    "    ###\n",
    "    \n",
    "    accuracy = list()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    ###\n",
    "    optimizer = get_optimizer(model, params)\n",
    "    ###\n",
    "    \n",
    "    if scheduler:\n",
    "        scheduler = CosineAnnealingLR(optimizer, EPOCHS-1, verbose=False)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        ### Training\n",
    "        model.train()\n",
    "        for samples, labels in training_batches:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(samples.float())\n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if scheduler: \n",
    "            scheduler.step()\n",
    "        \n",
    "        num_samples = 0\n",
    "        correct_predictions = 0\n",
    "        ### Testing\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for samples, labels in testing_batches:\n",
    "                output = model(samples.float())\n",
    "                correct_predictions += (output.argmax(dim=1) == labels).sum().item()\n",
    "                num_samples += labels.size(0)\n",
    "            \n",
    "        ###\n",
    "        accuracy.append(100.0 * correct_predictions / num_samples)\n",
    "        trial.report(accuracy[-1], epoch)\n",
    "        \n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "        ###\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f15a80-c768-4609-8166-2d5333e92e3c",
   "metadata": {},
   "source": [
    "> **Making final adaptations to the objective function**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69e1a20-e170-43bc-9a69-2168f5b1406f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:48:59.953047Z",
     "start_time": "2024-01-07T16:48:59.922632Z"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    params = {\n",
    "        'batch_size': trial.suggest_int('batch_size', 8, 128),\n",
    "        'optimizer': trial.suggest_categorical('optimizer', ['SGD', 'Adam', 'RMSprop']),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-5, 1e-1),\n",
    "        'weight_decay': trial.suggest_loguniform('weight_decay', 1e-5, 1e-1),\n",
    "        'scheduler': True if trial.suggest_int('scheduler', 0, 1) == 1 else False\n",
    "    }\n",
    "    \n",
    "    ###\n",
    "    model = get_model(trial)\n",
    "    ###\n",
    "    \n",
    "    training_batches, testing_batches = get_data(params)\n",
    "    \n",
    "    ###\n",
    "    history = train(model, training_batches, testing_batches, params, trial)\n",
    "    ###\n",
    "    \n",
    "    # Fitness-Value\n",
    "    return history[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6233421-3f5b-4b2e-96d1-43b115c2d3d7",
   "metadata": {},
   "source": [
    "> **Running the newly created study**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701d327b-30ba-4c3f-9087-e3a79608bbaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:50:14.764769Z",
     "start_time": "2024-01-07T16:49:01.217132Z"
    }
   },
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e52055-f3bd-4ca5-ab26-8cbf82b8ab8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:50:14.801117Z",
     "start_time": "2024-01-07T16:50:14.760468Z"
    }
   },
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b1f273-590e-48fa-8e48-9889d33c56ea",
   "metadata": {},
   "source": [
    "### Optuna Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba21492c-e724-47f9-af66-035dff95d1ce",
   "metadata": {},
   "source": [
    "This final section highlights various out-of-the-box visualizations offered by Optuna. Those visualizations can be very helpful when it comes to evaluating the importance of certain parameters in respect to the problem at hand. A comprehensive list of all available visualizations and their respective meaning can be found [here](https://optuna.readthedocs.io/en/stable/reference/visualization/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c5fd95-0e1d-4e31-b0e9-8445c41a8478",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:50:15.062897Z",
     "start_time": "2024-01-07T16:50:14.762863Z"
    }
   },
   "outputs": [],
   "source": [
    "# Matplotlib based visualizations\n",
    "optuna.visualization.matplotlib.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b43725-9038-4561-8386-232092d8ba84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:50:16.402439Z",
     "start_time": "2024-01-07T16:50:15.063855Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotly based visualizations\n",
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78826236-a316-400b-ac14-ec9470ed0598",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:50:16.404105Z",
     "start_time": "2024-01-07T16:50:16.360312Z"
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_intermediate_values(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358641d-2ed8-4d3a-8c78-4d6f9b4a324e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:50:16.404210Z",
     "start_time": "2024-01-07T16:50:16.361697Z"
    }
   },
   "outputs": [],
   "source": [
    "# Investigating a particular trial\n",
    "trials = study.get_trials()\n",
    "trials[14].params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c5d0b-add8-4da1-93cd-becc90b5d8a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:50:16.407469Z",
     "start_time": "2024-01-07T16:50:16.361946Z"
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4e56ea-62d9-447c-9d57-b18547056115",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-07T16:50:16.413328Z",
     "start_time": "2024-01-07T16:50:16.362554Z"
    }
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1055c379-300c-4e28-a57b-fb3203a1b66a",
   "metadata": {},
   "source": [
    "## Learning Outcomes\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d08326-d109-4d8c-871d-b39d98c69ee9",
   "metadata": {},
   "source": [
    "By the end of this section you should be able to:\n",
    "\n",
    "* grasp the fundamental differences between hyperparameters and model parameters, and why hyperparameter tuning is crucial for model performance;\n",
    "* recognize and list hyperparameters in various machine learning models, including those specific to neural networks & tree-based methods;\n",
    "* understand various hyperparameter optimization strategies, including Grid Search, Random Search, and Bayesian Optimization;\n",
    "* utilize Optuna for hyperparameter tuning, understand how to define the search space and run optimization trials in a structured and reproducible manner;\n",
    "* interpret optimization results, make informed decisions based on those results, and effectively communicate findings and choices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e99b4e32f7520d4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
